{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/g28594ashish/.local/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/g28594ashish/.local/lib/python2.7/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(r'/home/g28594ashish/13_AmazonFoodReview/Pre-Processing Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='X_train'\n",
    "infile = open(filename,'rb')\n",
    "X_train=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='y_train'\n",
    "infile = open(filename,'rb')\n",
    "y_train=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='X_test'\n",
    "infile = open(filename,'rb')\n",
    "X_test=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='y_test'\n",
    "infile = open(filename,'rb')\n",
    "y_test=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='Train_AvgW2V_std'\n",
    "infile = open(filename,'rb')\n",
    "X_train_AvgW2V_std=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='Test_AvgW2V_std'\n",
    "infile = open(filename,'rb')\n",
    "X_test_AvgW2V_std=pickle.load(infile)\n",
    "infile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch using L2 Regulizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model = GridSearchCV(LogisticRegression(), tuned_parameters, scoring = 'accuracy', cv=5,n_jobs=-1)\n",
    "model.fit(X_train_AvgW2V_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.8906198513528356\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(X_test_AvgW2V_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearch using L1 Regulizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'accuracy', cv=5,n_jobs=-1)\n",
    "model.fit(X_train_AvgW2V_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.8902537253322593\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(X_test_AvgW2V_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'penalty': ['l1', 'l2'], 'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7f3b6f05bfd0>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = uniform(loc=0, scale=1)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "model = RandomizedSearchCV(LogisticRegression(), hyperparameters, scoring = 'accuracy',cv=5, n_jobs=-1)\n",
    "model.fit(X_train_AvgW2V_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.047660479218970875, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
      "0.8906106982023212\n"
     ]
    }
   ],
   "source": [
    "print(model.best_estimator_)\n",
    "print(model.score(X_test_AvgW2V_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing the Performance,Error and Sparsity on Varying the Hyper-Parameter using L1 Regularizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('For C=', 10, 'Non-Zero elements =', 50, 'error=', 10.972796836671183)\n",
      "\n",
      "\n",
      "('For C=', 0.1, 'Non-Zero elements =', 50, 'error=', 10.958151795848126)\n",
      "\n",
      "\n",
      "('For C=', 0.01, 'Non-Zero elements =', 47, 'error=', 10.905063522864566)\n",
      "\n",
      "\n",
      "('For C=', 0.001, 'Non-Zero elements =', 33, 'error=', 11.134807600776186)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lamda in (10,0.1,0.01,0.001):\n",
    "    log_reg = LogisticRegression(C=lamda, penalty='l1');\n",
    "    log_reg.fit(X_train_AvgW2V_std, y_train);\n",
    "    w = log_reg.coef_\n",
    "    error=(1-log_reg.score(X_test_AvgW2V_std, y_test))*100\n",
    "    print (\"For C=\",lamda,\"Non-Zero elements =\" ,np.count_nonzero(w),\"error=\",error)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is observed that on increasing the lamda(1/C), the error of the model is increasing leading to underfit of the model and reducing the influence of loss term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Confusion matrix for Best Combination and better Accuracy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Training=0:00:07.075428\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start= datetime.now()\n",
    "\n",
    "best_log_reg=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "best_log_reg.fit(X_train_AvgW2V_std, y_train)\n",
    "# predict the response\n",
    "end= datetime.now()-start\n",
    "print ('Time taken for Training={}'.format(end))\n",
    "\n",
    "pred = best_log_reg.predict(X_test_AvgW2V_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nThe accuracy of the Logistitc Regression classifier(using AvgW2V vectorization) is ', 89.06198513528356)\n",
      "\n",
      "  CLASSIFICATION REPORT\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.73      0.48      0.58     17075\n",
      "   positive       0.91      0.97      0.94     92177\n",
      "\n",
      "avg / total       0.88      0.89      0.88    109252\n",
      "\n",
      "\n",
      "  CONFUSION MATRIX\n",
      "[[ 8220  8855]\n",
      " [ 3095 89082]]\n",
      "\n",
      "  Plot of CONFUSION MATRIX\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(y_test, pred) * 100\n",
    "print('\\nThe accuracy of the Logistitc Regression classifier(using AvgW2V vectorization) is ',acc)\n",
    "\n",
    "#Evaluate precission,recall,f1-score\n",
    "classification_report = classification_report(y_test, pred)\n",
    "print \"\\n  CLASSIFICATION REPORT\"\n",
    "print classification_report\n",
    "\n",
    "#determine Confusion matrix  and plotting\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print \"\\n  CONFUSION MATRIX\"\n",
    "print cm\n",
    "print \"\\n  Plot of CONFUSION MATRIX\"\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=['0','1'], normalize=True, title='Normalized confusion matrix', cmap = plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='Words_W2V_model_Train'\n",
    "infile = open(filename,'rb')\n",
    "w2v_model_train=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "filename='Words_W2V_model_Test'\n",
    "infile = open(filename,'rb')\n",
    "w2v_model_test=pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "\n",
    "filename='W2V_Words_Train'\n",
    "infile = open(filename,'rb')\n",
    "W2V_Words_Train=pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-Colinearity check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=best_log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(0,1)\n",
    "for i in range(len(X_train_AvgW2V_std)):\n",
    "    for j in range(50):\n",
    "        X_train_AvgW2V_std[i][j]+=noise        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for Training=0:00:08.900725\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "start= datetime.now()\n",
    "\n",
    "best_log_reg=LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
    "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
    "          verbose=0, warm_start=False)\n",
    "\n",
    "best_log_reg.fit(X_train_AvgW2V_std, y_train)\n",
    "# predict the response\n",
    "end= datetime.now()-start\n",
    "print ('Time taken for Training={}'.format(end))\n",
    "\n",
    "pred = best_log_reg.predict(X_test_AvgW2V_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_Noise = best_log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.94494252e-01,  1.02088772e+00, -3.74799310e-01,  3.44927949e-01,\n",
       "        3.14811613e-02,  6.01983194e-02, -5.36071374e-01, -3.53793392e-01,\n",
       "        3.20510140e-01, -4.01602186e-01,  3.79888804e-01,  3.88494944e-04,\n",
       "        8.91801234e-02, -1.54643785e-02,  5.24000320e-01,  1.81116758e-01,\n",
       "       -9.77891729e-03, -9.46099395e-02,  1.71706215e-01, -5.31947550e-01,\n",
       "        1.67268500e-01, -3.19856653e-01,  2.61985340e-01, -8.92448929e-02,\n",
       "       -1.60001469e-02,  2.04506006e-01,  7.38230629e-02, -3.41553511e-01,\n",
       "        7.12191228e-02, -1.78454429e-01, -2.40727468e-01, -7.66626683e-02,\n",
       "       -4.03172363e-01, -1.84198006e-01, -1.16083343e-01,  1.84526646e-01,\n",
       "       -6.88048600e-02, -4.00313633e-01, -2.81938355e-01, -1.56032870e-01,\n",
       "       -2.53289160e-01,  6.23376240e-02, -2.84794870e-01, -1.24961673e-01,\n",
       "        2.32254357e-01,  4.98046201e-01,  1.48947403e-01,  4.89085580e-01,\n",
       "       -2.37017365e-01, -1.27511402e-01])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.40121934,  1.02644736, -0.41803232,  0.32607159,  0.02416069,\n",
       "        0.06656912, -0.55496009, -0.36209279,  0.31071189, -0.41253196,\n",
       "        0.38737125, -0.01991127,  0.07269557, -0.04239846,  0.52032566,\n",
       "        0.21554665, -0.01259393, -0.08038984,  0.18301327, -0.55755381,\n",
       "        0.16075936, -0.31893514,  0.24404518, -0.09571301, -0.02722458,\n",
       "        0.21366856,  0.07081337, -0.33733894,  0.07857437, -0.20364585,\n",
       "       -0.24588282, -0.08948967, -0.40145258, -0.16541595, -0.13701104,\n",
       "        0.19201846, -0.10078528, -0.4296993 , -0.29347413, -0.18161876,\n",
       "       -0.26927136,  0.05156022, -0.26294567, -0.12261741,  0.24111819,\n",
       "        0.49208777,  0.17571429,  0.48278491, -0.24121756, -0.11985958])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_Noise[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "sum=[count+1 for i in range(len(W_Noise[0])) if (W_Noise[0,i]-w[0,i])/w[0,i]>=0.04]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(len(sum))/len(W_Noise[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that nearly 42% of the features have multi-colinearity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
